# # -*- coding: utf-8 -*-
# """MovieRecomendationSystem.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1MviWsyADv06O8L95NGXaDTWAYJTDvCS7

# importing libraries
# """

# import numpy as np
# import pandas as pd
# import difflib
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.metrics.pairwise import cosine_similarity

# """data processing"""

# dataset = pd.read_csv('movies.csv')
# dataset.head()

# dataset.shape

# # selecting important features
# required_features = ['genres','keywords','tagline','cast','director']
# required_features

# # removing null values
# for feature in required_features:
#   dataset[feature] = dataset[feature].fillna('')

# # combining required features
# combined_features = dataset['genres']+' '+dataset['keywords']+' '+dataset['tagline']+' '+dataset['cast']+' '+dataset['director']


# # vecotrizing the textual data
# vectorizer = TfidfVectorizer()
# feature_vecotrs = vectorizer.fit_transform(combined_features)

# # generating the similarity scores
# similarity = cosine_similarity(feature_vecotrs)

# # make a list of all the movie names
# all_movie_names = dataset['title'].tolist()

# movie_name = input('enter your favourite movie name: ')
# find_close_matches = difflib.get_close_matches(movie_name,all_movie_names)
# closest_match = find_close_matches[0]
# index_of_movie = dataset[dataset.title == closest_match]['index'].values[0]
# similarity_score = list(enumerate(similarity[index_of_movie]))
# # sort the moveis based on their similarity score
# sorted_similarity_score = sorted(similarity_score, key = lambda x:x[1], reverse=True)

# print("movies suggested for you: \n")
# i =1
# for movie in sorted_similarity_score:
#   index = movie[0]
#   title_from_index = dataset[dataset.index == index]['title'].values[0]
#   if(i<=30):
#     print(i,".", title_from_index)
#     i+=1


import numpy as np
import pandas as pd
import difflib
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from keys import key
import requests

API_key = key


def getMovieDetails(movie_name):
    url = f"http://www.omdbapi.com/?t={movie_name}&apikey={key}"
    response = requests.get(url)
    data = response.json()

    if data["Response"] == "True":
        poster_url = data["Poster"]
        imdb_url = f"https://www.imdb.com/title/{data['imdbID']}/"
        return poster_url, imdb_url
    else:
        return None, None

def shorten_title(title, max_length=15):
    return title if len(title) <= max_length else title[:max_length] + "..."

def show_movie_recomendations(recomended_movies):
    cols = st.columns(3, gap='large')

    for idx, movie in enumerate(recomended_movies):
        poster_url, imdb_url = getMovieDetails(movie)
        if poster_url:
            with cols[idx%3]:
                # st.image(poster_url, caption=movie, width=150)
                # st.markdown(f"[ðŸ”— View on IMDb]({imdb_url})", unsafe_allow_html=True)
                title = shorten_title(movie)
                st.markdown(
                    f"""
                    <a href="{imdb_url}" target="_blank">
                        <img src="{poster_url}" width="350" style="border-radius: 10px; margin-bottom: 5px;">
                    </a>
                    <p style="text-align:center; font-size: 14px; color: #ffffff;">{title}</p>
                    """,
                    unsafe_allow_html=True
                )
# Load Dataset
dataset = pd.read_csv('movies.csv')

# Select important features
required_features = ['genres', 'keywords', 'tagline', 'cast', 'director']

# Fill missing values
for feature in required_features:
    dataset[feature] = dataset[feature].fillna('')

# Combine all selected features into one string per movie
dataset['combined_features'] = dataset['genres'] + ' ' + dataset['keywords'] + ' ' + dataset['tagline'] + ' ' + dataset['cast'] + ' ' + dataset['director']

# Vectorize text data
vectorizer = TfidfVectorizer()
feature_vectors = vectorizer.fit_transform(dataset['combined_features'])

# Compute similarity scores
similarity = cosine_similarity(feature_vectors)
all_movie_names = dataset['title'].tolist()

st.markdown(
    """
    <style>
        .stApp {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }
        .stTextInput > div > div > input {
            text-align: center;  /* Center input text */
        }
        .stTextInput label {
            display: none;  /* Hide the 'Press Enter to apply' text */
        }
    </style>
    """,
    unsafe_allow_html=True
)

# Streamlit UI
st.title("ðŸŽ¬ Movie Recommendation System")
st.write("Enter a movie name to get similar movie suggestions.")

# Input field
movie_name = st.text_input("Enter your favorite movie:", label_visibility="collapsed")

if movie_name:
    # Find the closest matching movie
    find_close_matches = difflib.get_close_matches(movie_name, all_movie_names)

    if find_close_matches:
        closest_match = find_close_matches[0]
        movie_index = dataset[dataset.title == closest_match]['index'].values[0]

        similarity_score = list(enumerate(similarity[movie_index]))
        sorted_similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)

        st.subheader(f"Movies similar to {closest_match}:")
        
        recommended_movies = []
        for i, movie in enumerate(sorted_similarity_score[1:31]):  # Show top 10 recommendations
            index = movie[0]
            title_from_index = dataset[dataset.index == index]['title'].values[0]
            recommended_movies.append(title_from_index)

        # for i, movie in enumerate(recommended_movies):
        #     st.write(f"{i+1}. {movie}")
        show_movie_recomendations(recommended_movies)

    else:
        st.error("Movie not found! Try another title.")

